@inproceedings{GhavamzadehHierarchicalPG,
  title={Hierarchical Policy Gradient Algorithms},
  author={Mohammad Ghavamzadeh and Sridhar Mahadevan},
  booktitle={ICML},
  year={2003}
}


@article{Sutton1991ReinforcementLI,
  title={Reinforcement learning is direct adaptive optimal control},
  author={R. S. Sutton and A. G. Barto and R. J. Williams},
  journal={IEEE Control Systems},
  year={1991},
  volume={12},
  pages={19-22}
}

@inproceedings{Grudic2000LocalizingSI,
  title={Localizing Search in Reinforcement Learning},
  author={Gregory Z. Grudic and Lyle H. Ungar},
  booktitle={AAAI/IAAI},
  year={2000}
}

@article{Sutton1999BetweenMA,
  title={Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning},
  author={Richard S. Sutton and Doina Precup and Satinder P. Singh},
  journal={Artif. Intell.},
  year={1999},
  volume={112},
  pages={181-211}
}

@inproceedings{Thrun1994FindingSI,
  title={Finding Structure in Reinforcement Learning},
  author={Sebastian Thrun and Anton Schwartz},
  booktitle={NIPS},
  year={1994}
}


@inproceedings{Brooksbehaviors,
  title={Achieving Artificial Intelligence Through Building Robots},
  author={R.A. Brooks},
  booktitle={Technical Report A.I. Memo 899, Cambridge, MA: Massachusetts Institute of Technology Artificial Intelligence Laboratory},
  year={1986}
}

@article{Huber1997AFC,
  title={A feedback control structure for on-line learning tasks},
  author={Manfred Huber and Roderic A. Grupen},
  journal={Robotics and Autonomous Systems},
  year={1997},
  volume={22},
  pages={303-315}
}

@inproceedings{Parr1997ReinforcementLW,
  title={Reinforcement Learning with Hierarchies of Machines},
  author={Ronald Parr and Stuart J. Russell},
  booktitle={NIPS},
  year={1997}
}

@article{Dietterich2000HierarchicalRL,
  title={Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition},
  author={Thomas G. Dietterich},
  journal={J. Artif. Intell. Res.},
  year={2000},
  volume={13},
  pages={227-303}
}

@inproceedings{Marbach1998SimulationB,
  title={Simulation - Based Optimization of Markov},
  author={Peter Marbach},
  year={1998}
}

@article{Williams1992SimpleSG,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Ronald J. Williams},
  journal={Machine Learning},
  year={1992},
  volume={8},
  pages={229-256}
}

@inproceedings{Baxter1999DirectGR,
  title={Direct Gradient-Based Reinforcement Learning: I. Gradient Estimation Algorithms},
  author={Jonathan Baxter and Peter L. Bartlett},
  year={1999}
}


@article{Bartlett2001InfiniteHorizonPE,
  title={Infinite-Horizon Policy-Gradient Estimation},
  author={Peter L. Bartlett and Jonathan Baxter},
  journal={J. Artif. Intell. Res.},
  year={2001},
  volume={15},
  pages={319-350}  
 }
 
 @inproceedings{Sehnke2008PolicyGW,
  title={Policy Gradients with Parameter-Based Exploration for Control},
  author={Frank Sehnke and Christian Osendorfer and Thomas R{\"u}ckstie\ss and Alex Graves and Jan Peters and J{\"u}rgen Schmidhuber},
  booktitle={ICANN},
  year={2008}
}

@article{Peters:2008:NA:1352927.1352986,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Natural Actor-Critic},
 journal = {Neurocomput.},
 issue_date = {March, 2008},
 volume = {71},
 number = {7-9},
 month = mar,
 year = {2008},
 issn = {0925-2312},
 pages = {1180--1190},
 numpages = {11},
 url = {http://dx.doi.org/10.1016/j.neucom.2007.11.026},
 doi = {10.1016/j.neucom.2007.11.026},
 acmid = {1352986},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Actor-Critic methods, Compatible function approximation, Natural gradients, Policy-gradient methods, Reinforcement learning, Robot learning},
}

@article{Kober2008PolicySF,
  title={Policy search for motor primitives in robotics},
  author={Jens Kober and Jan Peters},
  journal={Machine Learning},
  year={2008},
  volume={84},
  pages={171-203}
}

@inproceedings{Peters2007ApplyingTE,
  title={Applying the Episodic Natural Actor-Critic Architecture to Motor Primitive Learning},
  author={Jan Peters and Stefan Schaal},
  booktitle={ESANN},
  year={2007}
}

@article{Daniel2012HierarchicalRE,
  title={Hierarchical Relative Entropy Policy Search},
  author={Christian Daniel and Gerhard Neumann and Jan Peters},
  journal={Journal of Machine Learning Research},
  year={2012},
  volume={17},
  pages={93:1-93:50}
}

@inproceedings{Peters2010RelativeEP,
  title={Relative Entropy Policy Search},
  author={Jan Peters and Katharina M{\"u}lling and Yasemin Altun},
  booktitle={AAAI},
  year={2010}
}
 
@article{aastrom1997computer,
  title={Computer-Controlled Systems, ser},
  author={{\AA}str{\"o}m, KJ and Wittenmark, Bjorn},
  journal={Information and systems sciences series. New Jersey: Prentice Hall},
  year={1997}
}


@incollection{Anderson:1990:CSC:104204.104226,
 author = {Anderson, Charles W. and Miller, W. Thomas},
 chapter = {A Challenging Set of Control Problems},
 title = {Neural Networks for Control},
 editor = {Miller,III, W. Thomas and Sutton, Richard S. and Werbos, Paul J.},
 year = {1990},
 isbn = {0-262-13261-3},
 pages = {475--508},
 numpages = {34},
 url = {http://dl.acm.org/citation.cfm?id=104204.104226},
 acmid = {104226},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@Misc{mushroom,
author = {D'Eramo, Carlo and Tateo, Davide},
title =  {{Mushroom}},
howpublished ={\url{https://github.com/AIRLab-POLIMI/mushroom}},
}


@inproceedings{shipsteeringACD,
  title={A Self-Learning Ship Steering Controller Based on Adaptive Critic Designs},
  author={Derong Liu, H. Daniel Pati\~no},
  booktitle={IFAC},
  year={1999}
}